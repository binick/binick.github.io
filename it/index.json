[{"content":"Uno delle cose pi√π complesse da gestire nello sviluppo di qualsiasi applicazione, dalle semplici applicazioni client alle pi√π complesse soluzioni enterprise, riguarda la gestione della persistenza.\nIn ambiente .NET parte di questa complessit√† pu√≤ essere gestita attraverso l‚Äôutilizzo delle migrazioni implementate internamente in Entity Framework.\nSpesso questa funzionalit√† √® vista come una utilit√† prettamente ad uso e consumo degli sviluppatori per aggiornare lo schema del database.\nQuando pensiamo di essere arrivati ad una situazione stabile eliminiamo tutte le migrazioni e partiamo da una situazione pulita.\nQuesta √® una frase che ho sentito davvero troppo spesso da molti colleghi, utilizzata in modo pi√π o meno consapevole, spesso i motivi che portano ad una esternalizzazione in tal senso √® una non sufficiente analisi del problema che genera molti cambiamenti, anche distruttivi, delle base dati.\nAltre volte pi√π consapevole e guidata dalla volont√† di non mantenere versioni precedenti a quella che supponiamo conterr√† dati \u0026ldquo;reali\u0026rdquo;, spesso questo coincide con il primo rilascio in produzione.\nIn realt√† quello che il tool ci offre √® un sistema di versionamento incrementale cosa che va ben oltre l\u0026rsquo;ambito di competenza dello sviluppatore coinvolgendo anche DBA o pi√π propriamente DBRE, consiglio l\u0026rsquo;ascolto dell\u0026rsquo;episodio Da DBA a DBRE, il nuovo approccio DevOps nel mondo database, con Alessandro Alpi di dotNET{podcast} se volete approfondire le sottili differenze fra i due ruoli.\nCome posso effettuare operazioni sui dati? Questa cosa √® una di quelle operazioni che non √® possibile istruire in una migrazione attraverso le API che Entity Framework ci mette a disposizione in quanto √® molto dipendente dal dominio e cercare di formalizzare ci√≤ attraverso delle API sarebbe stato molto complesso se non impossibile ed √® per questi casi che √® stata prevista la scappatoia per l\u0026rsquo;esecuzione di script SQL grezzi.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public partial class InitialWithSeed : Migration { protected override void Up(MigrationBuilder migrationBuilder) { migrationBuilder.Sql(@\u0026#34;CREATE TABLE Persons ( Id int, LastName varchar(255), FirstName varchar(255), Address varchar(255), City varchar(255) ); INSERT INTO Persons (Id, LastName, FirstName, Address, City) VALUES (1, \u0026#39;Nesfield\u0026#39;, \u0026#39;Carmelia\u0026#39;, \u0026#39;802 Knutson Drive\u0026#39;, \u0026#39;Krajan Dua Putukrejo\u0026#39;), (2, \u0026#39;Valentino\u0026#39;, \u0026#39;Daune\u0026#39;, \u0026#39;1464 Forest Dale Road\u0026#39;, \u0026#39;Prozor\u0026#39;), (3, \u0026#39;Chrstine\u0026#39;, \u0026#39;Gus\u0026#39;, \u0026#39;817 Bonner Park\u0026#39;, \u0026#39;Lukunor\u0026#39;), (4, \u0026#39;Tebb\u0026#39;, \u0026#39;Stearne\u0026#39;, \u0026#39;63138 Colorado Plaza\u0026#39;, \u0026#39;Sanjiang\u0026#39;), (5, \u0026#39;Dyne\u0026#39;, \u0026#39;Gibby\u0026#39;, \u0026#39;39613 Pond Road\u0026#39;, \u0026#39;Th√†nh Ph·ªë H·∫° Long\u0026#39;), (6, \u0026#39;MacShane\u0026#39;, \u0026#39;Sandra\u0026#39;, \u0026#39;02617 Continental Parkway\u0026#39;, \u0026#39;Cihambali\u0026#39;), (7, \u0026#39;Lissandri\u0026#39;, \u0026#39;Sidney\u0026#39;, \u0026#39;61 Talmadge Circle\u0026#39;, \u0026#39;Langar≈´d\u0026#39;), (8, \u0026#39;O\u0026#39;\u0026#39; Quirk\u0026#39;, \u0026#39;Marc\u0026#39;, \u0026#39;828 Ohio Avenue\u0026#39;, \u0026#39;Farafangana\u0026#39;), (9, \u0026#39;Mabee\u0026#39;, \u0026#39;Man\u0026#39;, \u0026#39;79 Crownhardt Street\u0026#39;, \u0026#39;Kembang\u0026#39;), (10, \u0026#39;Izak\u0026#39;, \u0026#39;Bertie\u0026#39;, \u0026#39;7 High Crossing Junction\u0026#39;, \u0026#39;Taodian\u0026#39;);\u0026#34;); } } L\u0026rsquo;esempio appena fatto potrebbe far storcere il naso ad entrambe le categorie.\nAgli sviluppatori perch√© sono presenti stringhe all\u0026rsquo;interno del sorgente e al DBRE perch√© si troverebbe a lavorare \u0026ldquo;scomodo\u0026rdquo; senza completamento automatico.\nCome far felici i due mondi? Una caratteristica del tool √® quella di generare delle classi parziali che vengono abbinate a classi contente in file denominati {MigrationId}.Design.cs\n1 2 3 4 5 6 [DbContext(typeof(DesignContext))] [Migration(\u0026#34;20220624071324_InitialWithSeed\u0026#34;)] partial class InitialWithSeed { ... } che contengono l\u0026rsquo;altra parte della classe parziale decorata con un attributo che ne identifica il contesto al quale √® legata ed uno che ne rappresenta l\u0026rsquo;identificativo.\nPossiamo quindi pensare di estrarre lo script SQL all\u0026rsquo;interno di un file con estensione .sql e sfruttare l\u0026rsquo;identificativo della migrazione a runtime per leggerlo ed integrarlo all\u0026rsquo;interno della migrazione.\nLa nostra migrazione avr√† quindi questo contenuto\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public partial class InitialWithSeed : Migration { protected override void Up(MigrationBuilder migrationBuilder) { var migrationAttribute = (MigrationAttribute)this.GetType() .GetCustomAttributes(typeof(MigrationAttribute), false) .Single(); migrationBuilder.Sql(File.ReadAllText(string.Format( CultureInfo.InvariantCulture, \u0026#34;{1}{0}RawMigrations{0}{2}\u0026#34;, Path.DirectorySeparatorChar, AppContext.BaseDirectory, $\u0026#34;{migrationAttribute.Id}.sql\u0026#34;))); } } e lo script SQL potr√† quindi essere letto dal percorso relativo alla directory di esecuzione /RawMigrations/20220624071324_InitialWithSeed.sql\nRicordiamoci inoltre di aggiungere l\u0026rsquo;istruzione\n1 2 3 \u0026lt;ItemGroup\u0026gt; \u0026lt;None Include=\u0026#34;RawMigrations\\*.sql\u0026#34; CopyToOutputDirectory=\u0026#34;PreserveNewest\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt; all\u0026rsquo;interno del .csproj per istruire MSBuild a pubblicare i file nella cartella di destinazione.\nCome sempre potete consultare il progetto dell\u0026rsquo;intero esempio su\nbinick / samples ","permalink":"https://binick.blog/it/2022/07/02/come-utilizzare-uno-script-sql-con-le-migrazioni-di-entity-framework/","summary":"\u003cp\u003eUno delle cose pi√π complesse da gestire nello sviluppo di qualsiasi applicazione, dalle semplici applicazioni client alle pi√π complesse soluzioni enterprise, riguarda la gestione della persistenza.\u003c/p\u003e\n\u003cp\u003eIn ambiente .NET parte di questa complessit√† pu√≤ essere gestita attraverso l‚Äôutilizzo delle \u003ca href=\"https://learn.microsoft.com/ef/core/managing-schemas/migrations/\"\u003emigrazioni\u003c/a\u003e implementate internamente in Entity Framework.\u003c/p\u003e\n\u003cp\u003eSpesso questa funzionalit√† √® vista come una utilit√† prettamente ad uso e consumo degli sviluppatori per aggiornare lo schema del database.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eQuando pensiamo di essere arrivati ad una situazione stabile eliminiamo tutte le migrazioni e partiamo da una situazione pulita.\u003c/p\u003e","title":"Come utilizzare uno script SQL con le migrazioni di Entity Framework?"},{"content":"Molti di voi sapranno che ormai da un po‚Äô di tempo, 13 anni1 ormai, GitHub offre un servizio chiamato Pages che consente di ospitare siti statici, molto comodo per ospitare blog e documentazione.\nPer questo non √® una novit√† che questo blog, come molti altri, sia ospitato proprio li. Ed il motivo non √® perch√©\u0026rsquo; \u0026ldquo;fa figo\u0026rdquo; ma molto pi√π concreto e venale.\nUno degli obbiettivi che mi ero prefissato era quello di non farlo diventare una spesa viva, per questo scelsi l\u0026rsquo;accoppiata HUGO + GitHub Pages, una scelta che oggi rifarei! Per una volta mi posso dare una pacca sulla spalla üôÇ.\nIn seguito, ho pensato che per avere una SEO migliore ed una maggiore associazione fra questo blog e me sarebbe stata buona cosa avere qualche dominio personalizzato.\nApplicare HTTPS. I domini li ho presi su ()register.it ed ho scelto di usare il servizio DNS di Cloudflare per cui dopo aver provveduto a configurare i record DNS in modo da supportare i domini personalizzati facendo puntare l\u0026rsquo;apex e www al sottodominio github.io.\nA questo punto nonostante la sezione Pages delle impostazioni del repo riportasse il flag sulla correttezza dei record DNS impostati il messaggio subito sotto mi informava che il dominio non era correttamente configurato\nAnche la sezione Custom domain names that are unsupported confermata la validit√† della configurazione e questa cosa mi ha causato un gran mal di testa fino a quando non ho trovato questo post dal quale cito testualmente.\nIf you‚Äôre configuring an apex domain make sure there are no other A, AAAA, or ALIAS records listed on the apex.\nIf you‚Äôre configuring a subdomain, www or otherwise, make sure there are no other A, AAAA, or CNAME records on that same subdomain.\nUn po\u0026rsquo; nello sconforto ho rimosso il record www ed a dispetto di quanto riportato dalla documentazione e della comparsa di questo warning\n(scusate ma mi sono dimenticato di catturare lo schermo üôè per cui l\u0026rsquo;ho recuperato da una issue dove ho scoperto che altre persone hanno avuto il mio stesso mal di testa)\nGitHub ha avviato il processo di creazione del certificato su Let\u0026rsquo;s Encrypt, successivamente ho riconfigurato i record DNS come in precedenza e finalmente.\nNon ho cosi tanta memoria ma Wikipedia attribuisce la prima release del servizio al 2008.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://binick.blog/it/2022/06/01/github-pages-ed-il-confusionario-processo-per-applicare-https/","summary":"\u003cp\u003eMolti di voi sapranno che ormai da un po‚Äô di tempo, 13 anni\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e ormai, GitHub offre un servizio chiamato \u003ca href=\"https://pages.github.com/\"\u003ePages\u003c/a\u003e che consente di ospitare siti statici, molto comodo per ospitare blog e documentazione.\u003c/p\u003e\n\u003cp\u003ePer questo non √® una novit√† che questo blog, come molti altri, sia ospitato proprio li. Ed il motivo non √® perch√©\u0026rsquo; \u0026ldquo;fa figo\u0026rdquo; ma molto pi√π concreto e venale.\u003cbr\u003e\nUno degli obbiettivi che mi ero prefissato era quello di non farlo diventare una spesa viva, per questo scelsi l\u0026rsquo;accoppiata \u003ca href=\"https://gohugo.io/\"\u003eHUGO\u003c/a\u003e + GitHub Pages, una scelta che oggi rifarei! Per una volta mi posso dare una pacca sulla spalla üôÇ.\u003c/p\u003e","title":"GitHub Pages ed il confusionario processo per applicare HTTPS"},{"content":" Recentemente mi √® stato chiesto di realizzare uno spike1 per valutare la fattibilit√† nella realizzazione di un\u0026rsquo;architettura micro frontends con Blazor Server.\nTi dico subito che √® stato un fallimento; ma andiamo con ordine, analizzando dapprima la declinazione del termine fallimento e le ragioni che mi hanno portato ad usarlo per poi cercare di ricapitolare quanto emerso da questa esplorazione che mi ha fatto giungere a questa conclusione.\nMi piace molto la definizione che da Treccani.\nRiconoscere l\u0026rsquo;inutilit√† dei propri sforzi, l\u0026rsquo;impossibilit√† e incapacit√† di raggiungere gli scopi fissati, rinunciando definitivamente alla lotta, all\u0026rsquo;azione.\n\u0026ndash; Treccani\nLo trovo particolarmente appropriato perch√© utilizza il termine scopi fissati, e quindi quali sono questi scopi?\nIl contesto conta. Nulla si fa per caso, e questa non √® certo un\u0026rsquo;eccezione. Il lavoro svolto √® parte di un contesto pi√π ampio che riguarda la necessit√† di migrare una serie di applicativi ASP.NET MVC 5 ad ASP.NET Core combinata alla volont√† di rendere l\u0026rsquo;attuale architettura pi√π flessibile introducendo il concetto di programmazione modulare2.\nSenza girarci troppo intorno, lo scopo finale era quello di misurare la fattibilit√† di \u0026ldquo;realizzare\u0026rdquo; un\u0026rsquo;architettura a micro frontends renderizzati lato server grazie a Blazor Server.\nA tal proposito sul blog di Martin Fowler √® presente un articolo bell\u0026rsquo;articolo di Cam Jackson nel quale viene fatta una panoramica su questa architettura e dal quale ho tradotto la loro definizione di micro frontends\nUno stile architettonico in cui le applicazioni frontend, consegnabili in modo indipendente, sono composte in un insieme pi√π grande.\n\u0026ndash; Thoughtworks su martinfowler.com\nHo messo realizzare fra virgolette in quanto la pubblicazione dei vari siti sarebbe avvenuta sempre e soltanto in modo unitario.\nMagari affronteremmo questo problema in un prossimo post.\nNon tutte le ciambelle riescono col buco. Andando dritti al punto, la motivazione principe che ha decretato il fallimento √® legata all\u0026rsquo;impossibilit√† di dare completa autonomia ai team, per due principali motivi ben precisi.\nOmonimia nel supporto alle pagine ed alle viste Razor. Per comporre il sito ogni frontend viene contenuto all\u0026rsquo;interno di una libreria di classi Razor la quale contiene anche la vista che si occupa di fare hosting dell\u0026rsquo;applicazione Blazor.\nQuesto √® reso possibile grazie alla funzionalit√† esposta dal SDK che consente ad una web app di utilizzare viste, pagine Razor o layout da librerie di classi e, come definito nella documentazione ufficiale, in caso di omonimia la precedenza viene data alla vista, pagina, layout presente nella web app.\nNel mio caso mi trovo in una situazione del genere\nFigura 1: una applicazione ASP.NET Core che referenzia due Razor Class Library che rappresentano due moduli.\ndove entrambi i moduli internamente fanno uso di layout contenuti al percorso /Pages/Shared/_Layout.cshtml.\nEcco, in questo caso accadrebbe che uno dei due team sarebbe scontento in quanto, se andasse bene vedrebbe la sua applicazione renderizzata all\u0026rsquo;interno di un altro layout, nel peggiore dei casi una parte o tutte le viste andrebbero in errore (es. una vista cerca di valorizzare una sezione non dichiarata nel layout).\nE notiamo bene che entrambi i moduli eseguiti indipendentemente si comporterebbero come atteso.\nLe rotte, il percorso di base che non vuole funzionare. Ho che almeno io non sono riuscito a far funzionare.\nAnche in questo caso, seguendo il principio dell\u0026rsquo;autonomia, il desiderata era quello di separare le rotte del modulo da quelle del contenitore, per esempio all\u0026rsquo;interno del Modulo A avremmo trovato / oppure /index mentre dal punto di vista del contenitore le rotte sarebbero state /module-a/ o /module-a/index.\nQuello che ho trovato √® stata una \u0026ldquo;coperta corta\u0026rdquo;, quando funzionava la navigazione interna al modulo non funzionava la generazione di rotte utilizzando Anchor Tag Helper (ricordo che questo spike √® frutto di un processo di migrazione), in quanto per la realizzazione del requisito ho utilizzato il middleware UsePathBaseMiddleware.\nQuesto ha comportato che nella generazione dei link all\u0026rsquo;interno del modulo verso l\u0026rsquo;esterno venisse aggiunto sempre il /module-a in testa all\u0026rsquo;indirizzo anche quanto il collegamento avrebbe dovuto semplicemente puntare la contenitore.\nDiversamente utilizzando il middleware sarei stato costretto ad utilizzare il nome del modulo in testa a tutte le direttive @page.\nConclusioni. Tirando le somme di quanto fatto e ragionando a mente fredda potrei dire che qualcosa di buono ce lo possiamo comunque portare a casa, infatti, non abilitando il supporto alle pagine e viste Razor in una RCL3 ed evitando l\u0026rsquo;utilizzo di Anchor Tag Helper nel markup HTML che contribuisce al rendering della vista non incorreremmo in questi problemi.\nUno spike √® un metodo di sviluppo del prodotto originato dalla programmazione estrema che utilizza il programma pi√π semplice possibile per esplorare potenziali soluzioni. Fonte Wikipedia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLa programmazione modulare √® una tecnica di progettazione software che enfatizza la separazione della funzionalit√† di un programma in moduli indipendenti e intercambiabili, in modo tale che ognuno contenga tutto il necessario per eseguire solo un aspetto della funzionalit√† desiderata. Fonte Wikipedia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLe librerie di classi Razor (RCL) sono state introdotte in ASP.NET Core 2.1 come metodo per impacchettare e distribuire componenti dell\u0026rsquo;interfaccia utente da referenziare e utilizzare all\u0026rsquo;interno di un\u0026rsquo;applicazione host.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://binick.blog/it/2022/05/22/micro-frontends-e-blazor-server-linizio-del-viaggio/","summary":"Non sempre le ciambelle riescono col buco ma questo non vuol dire che non ci sia del buono in loro. Sono incappato in una di queste nel tentativo di realizzare un\u0026rsquo;architettura a micro frontends con Blazor Server.","title":"Micro frontends e Blazor Server, l'inizio del viaggio"},{"content":"Recentemente il team Azure SDK ha rilasciato la prima versione stabile delle librerie per la gestione delle risorse.\nRaccolte sotto lo spazio dei nomi Azure.ResourceManager queste librerie andranno a sostituire tutte quelle attualmente presenti nello spazio dei nomi Microsoft.Azure.Management e a differenza delle precedenti saranno suddivide per servizio.\nDifferenze con Bicep e ARM templates. Se hai avuto modo di approvvigionare risorse Azure mediante uno di questi due pseudo-linguaggi hai sfruttato gli endpoint REST della risorsa deployments per la creazione dell\u0026rsquo;infrastruttura richiesta mediante il passaggio di un template in formato JSON strutturato e validato da un JSON Schema.\nLe ragioni per cui prendere in considerazione l\u0026rsquo;utilizzo dei template sono innumerevoli, oltre l\u0026rsquo;integrazione con Visual Studio Code e Visual Studio √® possibile distribuire le risorse ottenendo risultati ripetibili, mantenere uno storico delle distribuzioni e valutare la conformit√† agli standard aziendali attraverso i criteri di Azure.\nAzure.ResourceManager.Resources non implementa ‚Äúnativamente‚Äù questo concetto ma comunque ne consente l\u0026rsquo;utilizzo in quanto attraverso la classe ArmDeploymentCollection abbiamo modo operare sugli stessi endpoint REST utilizzati da Bicep e ARM templates.\nCreare una nuova distribuzione. Per ottenere una nuova distribuzione dobbiamo dotarci di un ArmClient passandogli un auth token con TokenCredential.\n1 2 3 using Azure.Identity; using Azure.ResourceManager; ArmClient client = new ArmClient(new DefaultAzureCredential()); Che ci consentir√† di accedere alla sottoscrizione predefinita, in base alle credenziali fornite, con await client.GetDefaultSubscriptionAsync() oppure all\u0026rsquo;ambito desiderato creando un identificativo della risorsa di interesse con ResourceIdentifier e passandolo ad uno dei metodi client.GetSubscriptionResource(id) o client.GetManagementGroupResource(id) o ancora client.GetResourceGroupResource(id).\nAd esempio:\n1 2 3 4 var id = ManagementGroupResource.CreateResourceIdentifier(\u0026#34;MY_MNGM_GROUP\u0026#34;); var managementGroup = client.GetManagementGroupResource(id); ArmDeploymentCollection deploymentCollection = managementGroup.GetArmDeployments(); Non ci resta che creare un\u0026rsquo;istanza di ArmDeploymentContent al quale possiamo passare il link ad un template esistente\n1 2 3 4 5 6 7 var deployment = new ArmDeploymentContent(new ArmDeploymentProperties(ArmDeploymentMode.Incremental) { TemplateLink = new ArmDeploymentTemplateLink { Uri = new Uri(\u0026#34;https://raw.githubusercontent.com/Azure/azure-docs-json-samples/master/azure-resource-manager/emptyrg.json\u0026#34;) }, }); oppure utilizzare la propriet√† Template per definire uno nostro.\nIn questo caso sar√† necessario costruire un oggetto di tipo BinaryData che rappresenti un JSON valido, ad esempio serializzando un dizionario.\n1 2 3 4 5 6 7 8 9 var emptyDeployment = new Dictionary\u0026lt;string, object\u0026gt;(); emptyDeployment.Add(\u0026#34;$schema\u0026#34;, \u0026#34;https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\u0026#34;); emptyDeployment.Add(\u0026#34;contentVersion\u0026#34;, \u0026#34;1.0.0.0\u0026#34;); emptyDeployment.Add(\u0026#34;resources\u0026#34;, Array.Empty\u0026lt;object\u0026gt;()); var deployment = new ArmDeploymentContent(new ArmDeploymentProperties(ArmDeploymentMode.Incremental) { Template = BinaryData.FromObjectAsJson(emptyDeployment) }); E successivamente effettuare la chiamata al metodo CreateOrUpdate per ottenere lo scopo.\n1 2 3 4 deploymentCollection.CreateOrUpdate( deploymentName: Guid.NewGuid().ToString(), content: deployment, waitUntil: WaitUntil.Started); Riferimenti utili. introduzione alla nuova esperienza di sviluppo: comparativa fra le vecchie librerie e le nuove principi progettuali alla base dell\u0026rsquo;SDK utili in caso doveste aprire segnalazioni di problemi incontrati nell\u0026rsquo;utilizzo lista comprensiva delle librerie attualmente in sviluppo: https://azure.github.io/azure-sdk/releases/latest/index.html?search=Azure.ResourceManager. ","permalink":"https://binick.blog/it/2022/05/09/utilizzare-i-modelli-arm-con-azure-sdk-per-.net/","summary":"\u003cp\u003eRecentemente il team \u003ca href=\"https://devblogs.microsoft.com/azure-sdk/azure-sdk-release-april-2022/\"\u003e\u003cem\u003eAzure SDK\u003c/em\u003e\u003c/a\u003e ha rilasciato la prima versione stabile delle librerie per la gestione delle risorse.\u003cbr\u003e\nRaccolte sotto lo spazio dei nomi \u003ccode\u003eAzure.ResourceManager\u003c/code\u003e queste librerie andranno a sostituire tutte quelle attualmente presenti nello spazio dei nomi \u003ccode\u003eMicrosoft.Azure.Management\u003c/code\u003e e a differenza delle precedenti saranno suddivide per servizio.\u003c/p\u003e\n\u003ch2 id=\"differenze-con-bicep-e-arm-templates\"\u003eDifferenze con \u003cem\u003eBicep\u003c/em\u003e e \u003cem\u003eARM templates\u003c/em\u003e.\u003c/h2\u003e\n\u003cp\u003eSe hai avuto modo di approvvigionare risorse \u003cem\u003eAzure\u003c/em\u003e mediante uno di questi due pseudo-linguaggi hai sfruttato gli endpoint REST della risorsa \u003ca href=\"https://docs.microsoft.com/rest/api/resources/deployments\"\u003e\u003cem\u003edeployments\u003c/em\u003e\u003c/a\u003e per la creazione dell\u0026rsquo;infrastruttura richiesta mediante il passaggio di un \u003ca href=\"https://docs.microsoft.com/azure/azure-resource-manager/templates/overview\"\u003e\u003cem\u003etemplate\u003c/em\u003e\u003c/a\u003e in formato \u003cem\u003eJSON\u003c/em\u003e strutturato e validato da un \u003cem\u003eJSON Schema\u003c/em\u003e.\u003c/p\u003e","title":"Utilizzare i modelli ARM con Azure SDK per .NET"},{"content":"Non sono uno scrittore, non lo sono mai stato e questa cosa la so sin dai temi a scuola. Ogni volta superare la colonna e mezzo era un\u0026rsquo;impresa.\nPubblicare articoli con regolarit√† mi porta via molto tempo, e non solo strettamente legato alla scrittura. Per questo ho tratto inspirazione da Troy Hunt ed ho pensato che creare un riepilogo mensile per aggiornarvi sul mio attuale stato e sulle possibili direzioni future potesse essere un buon investimento di tempo.\nQuesta cos√†, se riuscir√≤ a perseguirla nel tempo, sar√† utile anche a me un domani.\nRecap 0. Esattamente un mese fa da oggi ho annunciavo un nuovo side project. Bene, sono riuscito a creare la prima strategia riguardante la nomenclatura delle risorse in Azure.\nIl prossimo traguardo √® quello di definire le altre due strategie, relative alla localizzazione ed al tagging.\nHo inoltre in mente di creare un libreria in Python cosi da poter integrare il tutto nella Azure CLI.\nRiferimenti. Build your own Azure CLI Extensions: ottimo articolo su come creare una estensione della Azure CLI. ","permalink":"https://binick.blog/it/2022/04/29/monthly-recap-0/","summary":"\u003cp\u003eNon sono uno scrittore, non lo sono mai stato e questa cosa la so sin dai temi a scuola. Ogni volta superare la colonna e mezzo era un\u0026rsquo;impresa.\u003c/p\u003e\n\u003cp\u003ePubblicare articoli con regolarit√† mi porta via molto tempo, e non solo strettamente legato alla scrittura. Per questo ho tratto inspirazione da \u003ca href=\"https://www.troyhunt.com/tag/weekly-update/\"\u003eTroy Hunt\u003c/a\u003e ed ho pensato che creare un riepilogo mensile per aggiornarvi sul mio attuale stato e sulle possibili direzioni future potesse essere un buon investimento di tempo.\u003c/p\u003e","title":"Monthly recap 0"},{"content":"","permalink":"https://binick.blog/it/2022/04/14/migrare-un-database-sql-server-on-prem-in-azure-senza-downtime/","summary":"Il lift-and-shift √® la strategia che consente la migrazione su Cloud pi√π rapida, meno laboriosa e (almeno inizialmente) meno costosa rispetto ad altri processi.\u003cbr\u003e\nIn questo articolo vedremo come √® possibile migrare un database SQL Server senza generare interruzioni sui servizi gi√† in opera.","title":"Migrare un database SQL Server on-prem in Azure senza downtime"},{"content":"Qualche anno fa, quando ero un pendolare andavo a lavoro in auto, lungo il tragitto c‚Äôera un tratto di strada di campagna alberato che costeggiava un torrente. All‚Äôinterno di questa zona era presente una chicane molto stretta in uscita immediatamente successiva ad una lieve discesa che seguiva un lungo rettifilo. Data la presenza del torrente e l‚Äôombra permanente causata degli alberi non era cosa rara che in alcune mattinate d\u0026rsquo;inverno vi fosse la presenza di ghiaccio.\nNon ho mai avuto incidenti l√¨ in quanto ero a conoscenza del potenziale pericolo e nonostante il rettifilo portasse a spingere sull‚Äôacceleratore mi trattenevo.\nCosa voglio dirvi con questo aneddoto?\nChe prevenire √® meglio che curare?\nNon proprio, il messaggio √® pi√π sottile e riguarda l‚Äôistinto e la coscienza.\nCosa succederebbe se qualcuno passasse di l√¨ per caso in una di quelle mattine?\nE magari anche in ritardo per il suo appuntamento?\nCon molta probabilit√† sarebbe costretto a chiamare il carroattrezzi in quanto non consapevole della presenza di ghiaccio avrebbe pestato a fondo il pedale del freno per ridurre la velocit√† ad affrontare la curva. Con conseguente perdita di aderenza e ad auto in fossa.\nQuali sarebbero le potenziali conseguente?\nSupponiamo che dopo questa sfortunata ‚Äúavventura\u0026quot; l‚Äôautista esca incolume dall‚Äôauto, quali sarebbero le altre conseguenze?\nDirei due, un portafogli alleggerito ed un appuntamento mancato.\nUn tipico approccio all‚ÄôOpEx. Immagino vi starete domandando quale sia il fine ed il perch√© di questa parabola.\nDovete sapere che qualche tempo fa ho partecipato ad alcune riunioni inerenti alla migrazione di un applicativo aziendale ad uso interno in Azure nelle quali sono emerse molte problematiche dovute ai permessi assegnati agli utenti.\nProblemi che hanno causato lo slittamento del rilascio in produzione di un applicativo aziendale ad uso interno di oltre due settimane.\nProviamo, con non propriamente poco sforzo, a trasporre la parabola dello sfortunato autista all‚Äôinterno di questo contesto; possiamo identificare la strada come il cloud, la persona alla guida dell‚Äôauto come l‚Äôazienda. E direi di fermarci qui per il momento.\nTipicamente quando un‚Äôazienda si avvicina al cloud uno dei principali motivi di preoccupazione √® la gestione dei costi1.\nImmaginiamo di essere un membro del team di security operation, abituato ad operare su di un set di macchine predeterminato che adesso si ritrova con un potenziale parco macchine infinito ed un monito da parte del suo manager di area che gli dice di dover contenere le spese.\nL‚Äôunica cosa che conosce di pi√π simile a ci√≤ che ha usato finora √® il controllo dell‚Äôaccesso basato sui ruoli di Active Directory che trova il suo corrispettivo Azure RBAC configurabile anche da Azure Active Directory.\nVoi cosa fareste? Io credo che limiterei gli accessi a tutti gli utenti dando solo i permessi minimi necessari ai membri del team di sviluppo, ma penso che anche voi agireste cos√¨.\nE questo √® quello che il team ha fatto, per questo ha predisposto due gruppi di risorse, uno per ospitare tutte le risorse legate a tematiche di networking ed uno per il team di sviluppo dando loro il ruolo di Contributor per quest‚Äôultimo.\nScivolando in un uso improprio dei gruppi di risorse in modo improprio in quanto alcune risorse come per esempio il servizio Azure Kubernetes si appoggia ad un terzo gruppo di risorse per ospitare i nodi dei pool di agenti condiviso fra noi ed il servizio stesso.\nEducare piuttosto che imporre. Il team di SecOps ha fallito in quanto non a conoscenza del significato del termine Cloud Governance e gli strumenti che Azure offre a supporto.\nOvviamente il team ha agito in buona fede cercando di limitare l‚Äôambito2 di azione di ogni team.\nPensando di raggiungere due obbiettivi: controllo dei costi3 e sicurezza4.\nEcco che adesso abbiamo gli elementi necessari per riprendere la trasposizione iniziata precedentemente e identificare l‚Äôambito2 nel giaccio, la data di rilascio nell‚Äôappuntamento e le cinque discipline della governance del cloud nella consapevolezza.\nEcco che per cercare di aumentare questa consapevolezza ho creato questo repository\nbinick / oh-my-azure-playground il cui intento √® quello di definire degli standard basandosi sulle migliori pratiche emerse in tematiche come denominazione delle risorse, gestione dei tag e della localizzazione.\nSulle quali sar√† poi possibile definire dei pattern per la definizione di budget3.\nNel corso degli anni ho iniziato diversi side project ma mai nessuno ha avuto un post come questo.\nLo considero come un primo passo verso un impegno concreto, se volete approfondire o sentite la necessit√† di contribuire non esitate a contattarmi üôÇ.\nCapEx vs OpEx in Cloud Computing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nComprendere l\u0026rsquo;ambito per il controllo degli accessi in base al ruolo di Azure\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nChe cos\u0026rsquo;√® Gestione dei costi e fatturazione?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIntroduzione alla sicurezza di Azure\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://binick.blog/it/2022/03/29/un-nuovo-side-project/","summary":"\u003cp\u003eQualche anno fa, quando ero un pendolare andavo a lavoro in auto, lungo il tragitto c‚Äôera un tratto di strada di campagna alberato che costeggiava un torrente. All‚Äôinterno di questa zona era presente una chicane molto stretta in uscita immediatamente successiva ad una lieve discesa che seguiva un lungo rettifilo.\nData la presenza del torrente e l‚Äôombra permanente causata degli alberi non era cosa rara che in alcune mattinate d\u0026rsquo;inverno vi fosse la presenza di ghiaccio.\u003c/p\u003e","title":"Un nuovo side project"},{"content":" ","permalink":"https://binick.blog/it/2022/03/15/connettersi-ad-azure-sql-in-modo-sicuro-con-le-identit%C3%A0-gestite/","summary":"In quanto sviluppatori, siamo abituati a maneggiare chiavi, stringhe di connessione, certificati, nomi utente e password quotidianamente. Forse, proprio per la frequenza con la quale maneggiamo queste informazioni a volte pu√≤ capitare di abbassare la guardia e non dare loro il trattamento che meriterebbero, esponendoci inconsapevolmente a rischi non banali.","title":"Connettersi ad Azure SQL in modo sicuro con le identit√† gestite"},{"content":"Ho iniziato a lavorare in modalit√† remota a Marzo 2020, la ragione immagino la conosciamo tutti.\nComunque se un extra terrestre dovesse leggere questo post qua potr√† trovare maggiori informazioni https://wikipedia.org/wiki/COVID-19.\nL\u0026rsquo;esperienza √® stata quella di molti immagino, un uso massimo ed indiscriminato di piattaforme di comunicazione ed orecchi fumanti a fine giornata.\nQuest\u0026rsquo;esperienza √® andata avanti all\u0026rsquo;incirca per un anno e mezzo, 16 mesi per la precisione, fino a Luglio 2021 quando sono entrato in managed/designs.\nQui ho trovato un ambiente differente, alcuni lo definirebbero smart, votato alla crescita personale ed al miglioramento continuo, dove autonomia e fiducia sono due pilastri sulle quali si basa la collaborazione giornaliera.\nPrologo. Non sono mai stato un utilizzatore delle liste di cose da fare, forse per inesperienza o forse per qualche mia convinzione a me sconosciuta. Sta di fatto che il fallire sistematico nel seguire la lista della spesa ne √® una prova \u0026ldquo;Nicola non √® capace a gestire le liste\u0026rdquo;.\nUna volta presa consapevolezza di ci√≤ mi sono messo alla ricerca di possibili pattern e/o metodologie individuandone alcune che mi stanno accompagnando da un paio di mesi.\nLa mia inbox non √® la mail. Ho compreso che quello di cui ho bisogno non √® una lista di attivit√† da fare ma piuttosto una lista di cose che vorrei fare o che in qualche modo attira il mio interesse, credo che a livello inconscio il mio cervello prenda con ottimismo la mancanza di quel \u0026ldquo;da\u0026rdquo; che genera pressione per cose verso le quali non dovrebbe esserci.\nHo tre mail, quella aziendale ed altre due storiche che mi porto dietro da almeno un decennio, tutte e tre seguono la filosofia dell\u0026rsquo;Inbox Zero di Merlin Mann. Al momento le sfoglio due volte al giorno, all\u0026rsquo;incirca prima di pranzo e prima della fine della giornata, questi slot sono degli appuntamenti ricorrenti sul calendario fino al prossimo 29 di Giugno, vedremo se saranno prolungati ma credo di si.\nLa regola √® molto semplice:\n√® importante e deve essere eseguita in un preciso momento: viene creato un appuntamento sul calendario e viene archiviata nella relativa casella di posta √® importante: finisce nell\u0026rsquo;inbox e viene archiviata mi interessa: finisce nell\u0026rsquo;inbox e viene eliminata non mi interessa: finisce subito nel cestino In questo modo ho sempre le caselle di posta libere e riesco a mantenere l\u0026rsquo;attenzione sullo su quella decina di mail.\nSe arriva una mail che richiede un\u0026rsquo;interazione attiva non la eseguir√≤ subito ma come per le altre sottostar√† alle regole qui sopra.\nUna rana al giorno √® sufficiente. L\u0026rsquo;altra tecnica per me illuminante √® stata l\u0026rsquo;aver scoperto la regola dell'1-3-51 che trova fondamento sulla pratica di mangiare una rana appena svegli2. Ovviamente non fisicamente, non mi vorrei mai svegliare ed ultimamente dormo anche poco!\nPer cui il giorno prima faccio la lista di quello che vorrei fare l\u0026rsquo;indomani applicando una sorta di prioritizzazione delle attivit√† abbastanza empirica al momento stando sempre attendo che vi sia almeno una rana ed eventualmente altre attivit√† riempitive.\nEpilogo. Devo essere onesto, all‚Äôinizio ero scettico sull‚Äôimpiegare del tempo organizzare il mio domani. Devo riscredermi, il beneficio di scaricare il cervello dall\u0026rsquo;onere di pensare a cosa fare per non correre il rischio di perderla per sempre √® una cosa da non sottovalutare.\nAl momento la rigidit√† del calendario e la flessibilit√† che mi lascia la lista 1-3-5 sono un buon connubio. Solo il tempo sapr√† dire se √® una scelta per me vincente.\nWhy You Never Finish Your To-Do Lists at Work (And How to Change That) di Alex Cavoulacos\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEat That Frog: Brian Tracy Explains the Truth About Frogs di Brian Tracy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://binick.blog/it/2022/02/18/quella-volta-nella-quale-ho-assaggiato-una-rana/","summary":"\u003cp\u003eHo iniziato a lavorare in modalit√† remota a Marzo 2020, la ragione immagino la conosciamo tutti.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eComunque se un extra terrestre dovesse leggere questo post qua potr√† trovare maggiori informazioni \u003ca href=\"https://wikipedia.org/wiki/COVID-19\"\u003ehttps://wikipedia.org/wiki/COVID-19\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eL\u0026rsquo;esperienza √® stata quella di molti immagino, un uso massimo ed indiscriminato di piattaforme di comunicazione ed orecchi fumanti a fine giornata.\u003cbr\u003e\nQuest\u0026rsquo;esperienza √® andata avanti all\u0026rsquo;incirca per un anno e mezzo, 16 mesi per la precisione, fino a Luglio 2021 quando sono entrato in \u003ca href=\"https://www.manageddesigns.it/\"\u003e\u003cem\u003emanaged/designs\u003c/em\u003e\u003c/a\u003e.\u003c/p\u003e","title":"Quella volta nella quale ho assaggiato una rana"},{"content":"In un articolo precedente abbiamo visto Arricchire token JWT emessi da Azure Active Directory B2C.\nIn quell\u0026rsquo;articolo abbiamo parlato di come sia possibile aggiungere ad un JWT informazioni esterne a Microsoft Graph mediante l\u0026rsquo;uso di una Logic App ed un Blob Storage.\nIn questo invece vedremo come sia possibile creare una soluzioni che integri Azure Active Directory B2C.\nSeguendo la traccia di quanto trattato nel precedente articolo vedremo come salvare su Blob Storage dati fittizi alla registrazione di un utente.\nNote Nel resto dell\u0026rsquo;articolo ci sono riferimenti a risorse e concetti trattati nel precedente articolo al quale si rimanda. Panoramica della soluzione. La soluzione √® cosi composta:\nComposizione della soluzione\nread-customer-details-identity-la: rappresenta l\u0026rsquo;api il cui scopo √® reperire il contenuto del blob da customersstgacc (lo storage account) customer-register-tpc: √® il topic nel quale sono collezionati gli eventi di creazione di un nuovo utente customer-identity-details-filler-la: rappresenta l\u0026rsquo;api al quale spetta l\u0026rsquo;onere di generare dati fittizi che poi saranno salvati all\u0026rsquo;interno di un blob sullo customersstgacc contoso-b2c: √® il servizio di gestione degli accessi e delle identit√† offerto da Azure Introduzione ad Azure Event Grid. In Azure esiste un\u0026rsquo;implementazione del pattern publish/subscribe concepita per agevolare l\u0026rsquo;integrazione e la gestione delle risorse mediante un paradigma di sviluppo ad eventi.\nMediante Event Grid sar√† quindi possibile sottoscriversi a sorgenti di messaggi built-in attraverso una serie di gestori.\nQual\u0026rsquo;ora questo non fosse sufficiente √® comunque possibile creare dei topic personalizzati ai quali sar√† possibile sottoscriversi per riceverne gli eventi.\nCreazione di un topic personalizzato. Per la creazione di un topic √® possibile fare riferimento a questa guida.\nUna scelta da fare al momento della creazione del topic riguarda lo schema del contenuto della richiesta HTTP utilizzato. Gli schemi supportati al momento sono:\nEvent Grid Schema Cloud Event Schema Custom Input Schema, questo schema richieder√† la creazione di un\u0026rsquo;associazione fra le propriet√† dell\u0026rsquo;oggetto in ingresso e quelle richieste dallo Event Grid Schema. Il messaggio usato in questo caso ha la seguente struttura\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \u0026#34;data\u0026#34;: { \u0026#34;objectId\u0026#34;: \u0026#34;25100647-****-4571-****-b03e4ce72d02\u0026#34; // l\u0026#39;identificativo utile ad identificare l\u0026#39;utente }, \u0026#34;id\u0026#34;: \u0026#34;25100647-****-4571-****-b03e4ce72d02\u0026#34;, // l\u0026#39;identificativo univoco del messaggio, lo stesso di `data.objectId` in qesto caso \u0026#34;eventType\u0026#34;: \u0026#34;Microsoft.ActiveDirectory\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;*.onmicrosoft.com\u0026#34;, \u0026#34;dataVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;metadataVersion\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;eventTime\u0026#34;: \u0026#34;2021-12-03T21:04:03.8504745Z\u0026#34;, \u0026#34;topic\u0026#34;: \u0026#34;/subscriptions/{your-subscription-id}/resourceGroups/{your-resource-group}/providers/Microsoft.EventGrid/topics/{your-event-grid-topic}\u0026#34; } ] Emissione dell\u0026rsquo;evento di registrazione. L\u0026rsquo;invio degli eventi verso il topic avviene utilizzando un RESTful technical profile.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;TechnicalProfile Id=\u0026#34;AAD-UserEmitRegistrationEvent\u0026#34;\u0026gt; \u0026lt;DisplayName\u0026gt;Emit user registration event to Event Grid.\u0026lt;/DisplayName\u0026gt; \u0026lt;Protocol Name=\u0026#34;Proprietary\u0026#34; Handler=\u0026#34;Web.TPEngine.Providers.RestfulProvider, Web.TPEngine, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null\u0026#34; /\u0026gt; \u0026lt;Metadata\u0026gt; \u0026lt;Item Key=\u0026#34;ServiceUrl\u0026#34;\u0026gt;{Settings:CustomerRegisteredTopicUrl}\u0026lt;/Item\u0026gt; \u0026lt;Item Key=\u0026#34;AuthenticationType\u0026#34;\u0026gt;ApiKeyHeader\u0026lt;/Item\u0026gt; \u0026lt;Item Key=\u0026#34;SendClaimsIn\u0026#34;\u0026gt;Body\u0026lt;/Item\u0026gt; \u0026lt;Item Key=\u0026#34;ClaimUsedForRequestPayload\u0026#34;\u0026gt;userRegisterEvent\u0026lt;/Item\u0026gt; \u0026lt;Item Key=\u0026#34;DefaultUserMessageIfRequestFailed\u0026#34;\u0026gt;Cannot process your request right now, please try again later.\u0026lt;/Item\u0026gt; \u0026lt;/Metadata\u0026gt; \u0026lt;CryptographicKeys\u0026gt; \u0026lt;Key Id=\u0026#34;aeg-sas-key\u0026#34; StorageReferenceId=\u0026#34;B2C_1A_CustomerRegisteredTopicSas\u0026#34; /\u0026gt; \u0026lt;/CryptographicKeys\u0026gt; \u0026lt;InputClaimsTransformations\u0026gt; \u0026lt;InputClaimsTransformation ReferenceId=\u0026#34;GetSystemDateTime\u0026#34; /\u0026gt; \u0026lt;InputClaimsTransformation ReferenceId=\u0026#34;GenerateRegistrationEventRequest\u0026#34; /\u0026gt; \u0026lt;/InputClaimsTransformations\u0026gt; \u0026lt;InputClaims\u0026gt; \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;userRegisterEvent\u0026#34; /\u0026gt; \u0026lt;/InputClaims\u0026gt; \u0026lt;PersistedClaims\u0026gt; \u0026lt;PersistedClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; /\u0026gt; \u0026lt;/PersistedClaims\u0026gt; \u0026lt;UseTechnicalProfileForSessionManagement ReferenceId=\u0026#34;SM-AAD\u0026#34; /\u0026gt; \u0026lt;/TechnicalProfile\u0026gt; Questo frammento di markup tradotto in comando curl, per maggiore esplicabilit√†, risulterebbe cosi:\n1 curl -X POST -H \u0026#34;aeg-sas-key: $key\u0026#34; -d \u0026#34;$event\u0026#34; $endpoint dove i requisiti di autenticazione vengono soddisfatti dal metadato AuthenticationType al quale viene associata la chiave crittografica aeg-sas-key il cui valore viene recuperato dalla chiave B2C_1A_CustomerRegisteredTopicSas presente nella collezione delle chiavi dei criteri.\nTL;DR La scelta dello schema del topic in questo esempio √® stata guidata dalle limitazioni al momento imposte dal profilo tecnico RESTful riguardo alle possibilit√† di costruzione della richiesta HTTP, infatti per una combinazione di criteri non risulta possibile passare informazioni nelle intestazioni e nel corpo della richiesta allo stesso tempo.\nCi√≤ rende impossibile inviare verso un topic schemi di tipo Cloud Event in quanto il protocollo, nella versione 1.0 richiede la presenza di un\u0026rsquo;intestazione obbligatoria. Ben pi√π complessa √® la creazione del corpo della richiesta per la quale risultano necessario:\nutilizzare le InputClaimsTransformation aggiungere due attestazioni all\u0026rsquo;interno del bagaglio userRegisterEvent e systemDateTime entrambe di tipo stringa. Infine il profilo tecnico √® stato aggiunto fra i profili tecnici di validazione di LocalAccountSignUpWithLogonEmail in modo tale che l\u0026rsquo;evento venga emesso solamente in fase di registrazione di un\u0026rsquo;utente.\nUtilizzo delle trasformazioni delle attestazioni. Durante la creazione di criteri personalizzati potremmo avere la necessit√† di eseguire calcoli, come ad esempio il numero di tentativi di autenticazione, che seppur molto semplici risulterebbero impossibili senza l\u0026rsquo;esecuzioni di funzioni.\nQuesto requisito trova espressivit√† tramite le ClaimsTransformation il cui riferimento delle trasformazioni delle attestazioni contiene la lista completa delle trasformazioni utilizabili.\nNell\u0026rsquo;esempio sono stati utilizzati i metodi GetCurrentDateTime e GenerateJson\n1 2 3 4 5 \u0026lt;ClaimsTransformation Id=\u0026#34;GetSystemDateTime\u0026#34; TransformationMethod=\u0026#34;GetCurrentDateTime\u0026#34;\u0026gt; \u0026lt;OutputClaims\u0026gt; \u0026lt;OutputClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; TransformationClaimType=\u0026#34;currentDateTime\u0026#34; /\u0026gt; \u0026lt;/OutputClaims\u0026gt; \u0026lt;/ClaimsTransformation\u0026gt; GetSystemDateTime ha lo scopo di valorizzare l\u0026rsquo;attestazione systemDateTime\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;ClaimsTransformation Id=\u0026#34;GenerateRegistrationEventRequest\u0026#34; TransformationMethod=\u0026#34;GenerateJson\u0026#34;\u0026gt; \u0026lt;InputClaims\u0026gt; \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;objectId\u0026#34; TransformationClaimType=\u0026#34;0.data.objectId\u0026#34; /\u0026gt; \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;objectId\u0026#34; TransformationClaimType=\u0026#34;0.id\u0026#34; /\u0026gt; \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; TransformationClaimType=\u0026#34;0.eventTime\u0026#34; /\u0026gt; \u0026lt;/InputClaims\u0026gt; \u0026lt;InputParameters\u0026gt; \u0026lt;InputParameter Id=\u0026#34;0.dataVersion\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;1.0\u0026#34; /\u0026gt; \u0026lt;InputParameter Id=\u0026#34;0.eventType\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;Microsoft.ActiveDirectory\u0026#34; /\u0026gt; \u0026lt;InputParameter Id=\u0026#34;0.subject\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;{Settings:Tenant}\u0026#34; /\u0026gt; \u0026lt;/InputParameters\u0026gt; \u0026lt;OutputClaims\u0026gt; \u0026lt;OutputClaim ClaimTypeReferenceId=\u0026#34;userRegisterEvent\u0026#34; TransformationClaimType=\u0026#34;outputClaim\u0026#34; /\u0026gt; \u0026lt;/OutputClaims\u0026gt; \u0026lt;/ClaimsTransformation\u0026gt; GenerateRegistrationEventRequest ha invece l\u0026rsquo;onere di costruire il JSON e valorizzare l\u0026rsquo;attestazione userRegisterEvent.\nConclusioni. In questo articolo abbiamo visto come mediante Identity Experience Framework sia possibile integrare un tenant B2C con la nostra infrastruttura ed aprire eventuali scenari di sviluppo interessanti.\nPer farlo abbiamo toccato Azure Event Grid e come creare un Event Grid Topic.\nInfine come sia possibile manipolare delle attestazioni ed utilizzarle all\u0026rsquo;interno dei profili tecnici.\nSe foste interessati all‚Äôesempio completo lo potrete trovare al seguente indirizzo https://github.com/binick/samples/tree/master/src/enrich-a-jwt-token-with-ief.\n","permalink":"https://binick.blog/it/2022/01/08/sviluppare-soluzioni-integrate-con-active-directory-b2c-ed-azure-event-grid./","summary":"\u003cp\u003eIn un articolo precedente abbiamo visto \u003ca href=\"https://www.ugidotnet.org/tip/2873/Arricchire-JWT-emessi-da-Active-Directory-B2C-con-criteri-personalizzati\" title=\"Arricchire token JWT emessi da Azure Active Directory B2C.\" target=\"_blank\"\u003eArricchire token JWT emessi da Azure Active Directory B2C\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIn quell\u0026rsquo;articolo abbiamo parlato di come sia possibile aggiungere ad un JWT informazioni esterne a \u003cem\u003eMicrosoft Graph\u003c/em\u003e mediante l\u0026rsquo;uso di una \u003cem\u003eLogic App\u003c/em\u003e ed un \u003cem\u003eBlob Storage\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eIn questo invece vedremo come sia possibile creare una soluzioni che integri \u003cem\u003eAzure Active Directory B2C\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eSeguendo la traccia di quanto trattato nel precedente articolo vedremo come salvare su \u003cem\u003eBlob Storage\u003c/em\u003e dati fittizi alla registrazione di un utente.\u003c/p\u003e","title":"Sviluppare soluzioni integrate con Active Directory B2C ed Azure Event Grid."},{"content":" ","permalink":"https://binick.blog/it/2021/12/27/arricchire-token-jwt-emessi-da-azure-active-directory-b2c/","summary":"Personalizzare un JSON Web Token emesso da Azure Active Directory B2C con informazioni presenti su un sistema esterno √® possibile: √® sufficiente, infatti, sfruttare le possibilit√† di personalizzazione offerte dai criteri personalizzati.","title":"Arricchire token JWT emessi da Azure Active Directory B2C"},{"content":"","permalink":"https://binick.blog/it/about-me/","summary":"Chi sono","title":"Chi sono"}]