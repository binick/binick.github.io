[{"content":" body.dark .post-content img[src$=\"art-assemblies-graph.drawio.svg\"] { filter: invert(90%); }  Recentemente mi è stato chiesto di realizzare uno spike1 per valutare la fattibilità nella realizzazione di un\u0026rsquo;architettura micro frontends con Blazor Server.\nTi dico subito che è stato un fallimento; ma andiamo con ordine, analizzando dapprima la declinazione del termine fallimento e le ragioni che mi hanno portato ad usarlo per poi cercare di ricapitolare quanto emerso da questa esplorazione che mi ha fatto giungere a questa conclusione.\nMi piace molto la definizione che da Treccani.\n Riconoscere l\u0026rsquo;inutilità dei propri sforzi, l\u0026rsquo;impossibilità e incapacità di raggiungere gli scopi fissati, rinunciando definitivamente alla lotta, all\u0026rsquo;azione.\n\u0026ndash; Treccani\n Lo trovo particolarmente appropriato perché utilizza il termine scopi fissati, e quindi quali sono questi scopi?\nIl contesto conta. Nulla si fa per caso, e questa non è certo un\u0026rsquo;eccezione. Il lavoro svolto è parte di un contesto più ampio che riguarda la necessità di migrare una serie di applicativi ASP.NET MVC 5 ad ASP.NET Core combinata alla volontà di rendere l\u0026rsquo;attuale architettura più flessibile introducendo il concetto di programmazione modulare2.\nSenza girarci troppo intorno, lo scopo finale era quello di misurare la fattibilità di \u0026ldquo;realizzare\u0026rdquo; un\u0026rsquo;architettura a micro frontends renderizzati lato server grazie a Blazor Server.\nA tal proposito sul blog di Martin Fowler è presente un articolo bell\u0026rsquo;articolo di Cam Jackson nel quale viene fatta una panoramica su questa architettura e dal quale ho tradotto la loro definizione di micro frontends\n Uno stile architettonico in cui le applicazioni frontend, consegnabili in modo indipendente, sono composte in un insieme più grande.\n\u0026ndash; Thoughtworks su martinfowler.com\n Ho messo realizzare fra virgolette in quanto la pubblicazione dei vari siti sarebbe avvenuta sempre e soltanto in modo unitario.\nMagari affronteremmo questo problema in un prossimo post.\nNon tutte le ciambelle riescono col buco. Andando dritti al punto, la motivazione principe che ha decretato il fallimento è legata all\u0026rsquo;impossibilità di dare completa autonomia ai team, per due principali motivi ben precisi.\nOmonimia nel supporto alle pagine ed alle viste Razor. Per comporre il sito ogni frontend viene contenuto all\u0026rsquo;interno di una libreria di classi Razor la quale contiene anche la vista che si occupa di fare hosting dell\u0026rsquo;applicazione Blazor.\nQuesto è reso possibile grazie alla funzionalità esposta dal SDK che consente ad una web app di utilizzare viste, pagine Razor o layout da librerie di classi e, come definito nella documentazione ufficiale, in caso di omonimia la precedenza viene data alla vista, pagina, layout presente nella web app.\nNel mio caso mi trovo in una situazione del genere\n  Figura 1: una applicazione ASP.NET Core che referenzia due Razor Class Library che rappresentano due moduli.\n  dove entrambi i moduli internamente fanno uso di layout contenuti al percorso /Pages/Shared/_Layout.cshtml.\nEcco, in questo caso accadrebbe che uno dei due team sarebbe scontento in quanto, se andasse bene vedrebbe la sua applicazione renderizzata all\u0026rsquo;interno di un altro layout, nel peggiore dei casi una parte o tutte le viste andrebbero in errore (es. una vista cerca di valorizzare una sezione non dichiarata nel layout).\nE notiamo bene che entrambi i moduli eseguiti indipendentemente si comporterebbero come atteso.\nLe rotte, il percorso di base che non vuole funzionare. Ho che almeno io non sono riuscito a far funzionare.\nAnche in questo caso, seguendo il principio dell\u0026rsquo;autonomia, il desiderata era quello di separare le rotte del modulo da quelle del contenitore, per esempio all\u0026rsquo;interno del Modulo A avremmo trovato / oppure /index mentre dal punto di vista del contenitore le rotte sarebbero state /module-a/ o /module-a/index.\nQuello che ho trovato è stata una \u0026ldquo;coperta corta\u0026rdquo;, quando funzionava la navigazione interna al modulo non funzionava la generazione di rotte utilizzando Anchor Tag Helper (ricordo che questo spike è frutto di un processo di migrazione), in quanto per la realizzazione del requisito ho utilizzato il middleware UsePathBaseMiddleware.\nQuesto ha comportato che nella generazione dei link all\u0026rsquo;interno del modulo verso l\u0026rsquo;esterno venisse aggiunto sempre il /module-a in testa all\u0026rsquo;indirizzo anche quanto il collegamento avrebbe dovuto semplicemente puntare la contenitore.\nDiversamente utilizzando il middleware sarei stato costretto ad utilizzare il nome del modulo in testa a tutte le direttive @page.\nConclusioni. Tirando le somme di quanto fatto e ragionando a mente fredda potrei dire che qualcosa di buono ce lo possiamo comunque portare a casa, infatti, non abilitando il supporto alle pagine e viste Razor in una RCL3 ed evitando l\u0026rsquo;utilizzo di Anchor Tag Helper nel markup HTML che contribuisce al rendering della vista non incorreremmo in questi problemi.\n  Uno spike è un metodo di sviluppo del prodotto originato dalla programmazione estrema che utilizza il programma più semplice possibile per esplorare potenziali soluzioni. Fonte Wikipedia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n La programmazione modulare è una tecnica di progettazione software che enfatizza la separazione della funzionalità di un programma in moduli indipendenti e intercambiabili, in modo tale che ognuno contenga tutto il necessario per eseguire solo un aspetto della funzionalità desiderata. Fonte Wikipedia.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Le librerie di classi Razor (RCL) sono state introdotte in ASP.NET Core 2.1 come metodo per impacchettare e distribuire componenti dell\u0026rsquo;interfaccia utente da referenziare e utilizzare all\u0026rsquo;interno di un\u0026rsquo;applicazione host.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://binick.blog/it/2022/05/22/micro-frontends-with-blazor-start-of-the-journay/","summary":"Non sempre le ciambelle riescono col buco ma questo non vuol dire che non ci sia del buono in loro. Sono incappato in una di queste nel tentativo di realizzare un\u0026rsquo;architettura a micro frontends con Blazor Server.","title":"Micro frontends e Blazor Server, l'inizio del viaggio"},{"content":"Non sono uno scrittore, non lo sono mai stato e questa cosa la so sin dai temi a scuola. Ogni volta superare la colonna e mezzo era un\u0026rsquo;impresa.\nPubblicare articoli con regolarità mi porta via molto tempo, e non solo strettamente legato alla scrittura. Per questo ho tratto inspirazione da Troy Hunt ed ho pensato che creare un riepilogo mensile per aggiornarvi sul mio attuale stato e sulle possibili direzioni future potesse essere un buon investimento di tempo.\nQuesta cosà, se riuscirò a perseguirla nel tempo, sarà utile anche a me un domani.\nRecap 0. Esattamente un mese fa da oggi ho annunciavo un nuovo side project. Bene, sono riuscito a creare la prima strategia riguardante la nomenclatura delle risorse in Azure.\nIl prossimo traguardo è quello di definire le altre due strategie, relative alla localizzazione ed al tagging.\nHo inoltre in mente di creare un libreria in Python cosi da poter integrare il tutto nella Azure CLI.\nRiferimenti.  Build your own Azure CLI Extensions: ottimo articolo su come creare una estensione della Azure CLI.  ","permalink":"https://binick.blog/it/2022/04/29/0/","summary":"Non sono uno scrittore, non lo sono mai stato e questa cosa la so sin dai temi a scuola. Ogni volta superare la colonna e mezzo era un\u0026rsquo;impresa.\nPubblicare articoli con regolarità mi porta via molto tempo, e non solo strettamente legato alla scrittura. Per questo ho tratto inspirazione da Troy Hunt ed ho pensato che creare un riepilogo mensile per aggiornarvi sul mio attuale stato e sulle possibili direzioni future potesse essere un buon investimento di tempo.","title":"Monthly recap 0"},{"content":"","permalink":"https://binick.blog/it/2022/04/14/migrate-sql-server-to-azure/","summary":"Il lift-and-shift è la strategia che consente la migrazione su Cloud più rapida, meno laboriosa e (almeno inizialmente) meno costosa rispetto ad altri processi.\u003cbr\u003e\nIn questo articolo vedremo come è possibile migrare un database SQL Server senza generare interruzioni sui servizi già in opera.","title":"Migrare un database SQL Server on-prem in Azure senza downtime"},{"content":"Qualche anno fa, quando ero un pendolare andavo a lavoro in auto, lungo il tragitto c’era un tratto di strada di campagna alberato che costeggiava un torrente. All’interno di questa zona era presente una chicane molto stretta in uscita immediatamente successiva ad una lieve discesa che seguiva un lungo rettifilo. Data la presenza del torrente e l’ombra permanente causata degli alberi non era cosa rara che in alcune mattinate d\u0026rsquo;inverno vi fosse la presenza di ghiaccio.\nNon ho mai avuto incidenti lì in quanto ero a conoscenza del potenziale pericolo e nonostante il rettifilo portasse a spingere sull’acceleratore mi trattenevo.\nCosa voglio dirvi con questo aneddoto?\nChe prevenire è meglio che curare?\nNon proprio, il messaggio è più sottile e riguarda l’istinto e la coscienza.\nCosa succederebbe se qualcuno passasse di lì per caso in una di quelle mattine?\nE magari anche in ritardo per il suo appuntamento?\nCon molta probabilità sarebbe costretto a chiamare il carroattrezzi in quanto non consapevole della presenza di ghiaccio avrebbe pestato a fondo il pedale del freno per ridurre la velocità ad affrontare la curva. Con conseguente perdita di aderenza e ad auto in fossa.\nQuali sarebbero le potenziali conseguente?\nSupponiamo che dopo questa sfortunata “avventura\u0026quot; l’autista esca incolume dall’auto, quali sarebbero le altre conseguenze?\nDirei due, un portafogli alleggerito ed un appuntamento mancato.\nUn tipico approccio all’OpEx. Immagino vi starete domandando quale sia il fine ed il perché di questa parabola.\nDovete sapere che qualche tempo fa ho partecipato ad alcune riunioni inerenti alla migrazione di un applicativo aziendale ad uso interno in Azure nelle quali sono emerse molte problematiche dovute ai permessi assegnati agli utenti.\nProblemi che hanno causato lo slittamento del rilascio in produzione di un applicativo aziendale ad uso interno di oltre due settimane.\nProviamo, con non propriamente poco sforzo, a trasporre la parabola dello sfortunato autista all’interno di questo contesto; possiamo identificare la strada come il cloud, la persona alla guida dell’auto come l’azienda. E direi di fermarci qui per il momento.\nTipicamente quando un’azienda si avvicina al cloud uno dei principali motivi di preoccupazione è la gestione dei costi1.\nImmaginiamo di essere un membro del team di security operation, abituato ad operare su di un set di macchine predeterminato che adesso si ritrova con un potenziale parco macchine infinito ed un monito da parte del suo manager di area che gli dice di dover contenere le spese.\nL’unica cosa che conosce di più simile a ciò che ha usato finora è il controllo dell’accesso basato sui ruoli di Active Directory che trova il suo corrispettivo Azure RBAC configurabile anche da Azure Active Directory.\nVoi cosa fareste? Io credo che limiterei gli accessi a tutti gli utenti dando solo i permessi minimi necessari ai membri del team di sviluppo, ma penso che anche voi agireste così.\nE questo è quello che il team ha fatto, per questo ha predisposto due gruppi di risorse, uno per ospitare tutte le risorse legate a tematiche di networking ed uno per il team di sviluppo dando loro il ruolo di Contributor per quest’ultimo.\nScivolando in un uso improprio dei gruppi di risorse in modo improprio in quanto alcune risorse come per esempio il servizio Azure Kubernetes si appoggia ad un terzo gruppo di risorse per ospitare i nodi dei pool di agenti condiviso fra noi ed il servizio stesso.\nEducare piuttosto che imporre. Il team di SecOps ha fallito in quanto non a conoscenza del significato del termine Cloud Governance e gli strumenti che Azure offre a supporto.\n  Ovviamente il team ha agito in buona fede cercando di limitare l’ambito2 di azione di ogni team.\nPensando di raggiungere due obbiettivi: controllo dei costi3 e sicurezza4.\nEcco che adesso abbiamo gli elementi necessari per riprendere la trasposizione iniziata precedentemente e identificare l’ambito2 nel giaccio, la data di rilascio nell’appuntamento e le cinque discipline della governance del cloud nella consapevolezza.\nEcco che per cercare di aumentare questa consapevolezza ho creato questo repository\n binick / oh-my-azure-playground   il cui intento è quello di definire degli standard basandosi sulle migliori pratiche emerse in tematiche come denominazione delle risorse, gestione dei tag e della localizzazione.\nSulle quali sarà poi possibile definire dei pattern per la definizione di budget3.\nNel corso degli anni ho iniziato diversi side project ma mai nessuno ha avuto un post come questo.\nLo considero come un primo passo verso un impegno concreto, se volete approfondire o sentite la necessità di contribuire non esitate a contattarmi 🙂.\n  CapEx vs OpEx in Cloud Computing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Comprendere l\u0026rsquo;ambito per il controllo degli accessi in base al ruolo di Azure\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Che cos\u0026rsquo;è Gestione dei costi e fatturazione?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Introduzione alla sicurezza di Azure\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://binick.blog/it/2022/03/29/cloud-governance/","summary":"Qualche anno fa, quando ero un pendolare andavo a lavoro in auto, lungo il tragitto c’era un tratto di strada di campagna alberato che costeggiava un torrente. All’interno di questa zona era presente una chicane molto stretta in uscita immediatamente successiva ad una lieve discesa che seguiva un lungo rettifilo. Data la presenza del torrente e l’ombra permanente causata degli alberi non era cosa rara che in alcune mattinate d\u0026rsquo;inverno vi fosse la presenza di ghiaccio.","title":"Un nuovo side project"},{"content":"","permalink":"https://binick.blog/it/2022/03/15/connect-to-azuresql-with-managed-identities/","summary":"In quanto sviluppatori, siamo abituati a maneggiare chiavi, stringhe di connessione, certificati, nomi utente e password quotidianamente. Forse, proprio per la frequenza con la quale maneggiamo queste informazioni a volte può capitare di abbassare la guardia e non dare loro il trattamento che meriterebbero, esponendoci inconsapevolmente a rischi non banali.","title":"Connettersi ad Azure SQL in modo sicuro con le identità gestite"},{"content":"Ho iniziato a lavorare in modalità remota a Marzo 2020, la ragione immagino la conosciamo tutti.\n Comunque se un extra terrestre dovesse leggere questo post qua potrà trovare maggiori informazioni https://wikipedia.org/wiki/COVID-19.\n L\u0026rsquo;esperienza è stata quella di molti immagino, un uso massimo ed indiscriminato di piattaforme di comunicazione ed orecchi fumanti a fine giornata.\nQuest\u0026rsquo;esperienza è andata avanti all\u0026rsquo;incirca per un anno e mezzo, 16 mesi per la precisione, fino a Luglio 2021 quando sono entrato in managed/designs.\nQui ho trovato un ambiente differente, alcuni lo definirebbero smart, votato alla crescita personale ed al miglioramento continuo, dove autonomia e fiducia sono due pilastri sulle quali si basa la collaborazione giornaliera.\nPrologo. Non sono mai stato un utilizzatore delle liste di cose da fare, forse per inesperienza o forse per qualche mia convinzione a me sconosciuta. Sta di fatto che il fallire sistematico nel seguire la lista della spesa ne è una prova \u0026ldquo;Nicola non è capace a gestire le liste\u0026rdquo;.\nUna volta presa consapevolezza di ciò mi sono messo alla ricerca di possibili pattern e/o metodologie individuandone alcune che mi stanno accompagnando da un paio di mesi.\nLa mia inbox non è la mail. Ho compreso che quello di cui ho bisogno non è una lista di attività da fare ma piuttosto una lista di cose che vorrei fare o che in qualche modo attira il mio interesse, credo che a livello inconscio il mio cervello prenda con ottimismo la mancanza di quel \u0026ldquo;da\u0026rdquo; che genera pressione per cose verso le quali non dovrebbe esserci.\nHo tre mail, quella aziendale ed altre due storiche che mi porto dietro da almeno un decennio, tutte e tre seguono la filosofia dell'Inbox Zero di Merlin Mann. Al momento le sfoglio due volte al giorno, all\u0026rsquo;incirca prima di pranzo e prima della fine della giornata, questi slot sono degli appuntamenti ricorrenti sul calendario fino al prossimo 29 di Giugno, vedremo se saranno prolungati ma credo di si.\nLa regola è molto semplice:\n è importante e deve essere eseguita in un preciso momento: viene creato un appuntamento sul calendario e viene archiviata nella relativa casella di posta è importante: finisce nell'inbox e viene archiviata mi interessa: finisce nell'inbox e viene eliminata non mi interessa: finisce subito nel cestino  In questo modo ho sempre le caselle di posta libere e riesco a mantenere l\u0026rsquo;attenzione sullo su quella decina di mail.\nSe arriva una mail che richiede un\u0026rsquo;interazione attiva non la eseguirò subito ma come per le altre sottostarà alle regole qui sopra.\nUna rana al giorno è sufficiente. L\u0026rsquo;altra tecnica per me illuminante è stata l\u0026rsquo;aver scoperto la regola dell'1-3-51 che trova fondamento sulla pratica di mangiare una rana appena svegli2. Ovviamente non fisicamente, non mi vorrei mai svegliare ed ultimamente dormo anche poco!\nPer cui il giorno prima faccio la lista di quello che vorrei fare l\u0026rsquo;indomani applicando una sorta di prioritizzazione delle attività abbastanza empirica al momento stando sempre attendo che vi sia almeno una rana ed eventualmente altre attività riempitive.\nEpilogo. Devo essere onesto, all’inizio ero scettico sull’impiegare del tempo organizzare il mio domani. Devo riscredermi, il beneficio di scaricare il cervello dall\u0026rsquo;onere di pensare a cosa fare per non correre il rischio di perderla per sempre è una cosa da non sottovalutare.\nAl momento la rigidità del calendario e la flessibilità che mi lascia la lista 1-3-5 sono un buon connubio. Solo il tempo saprà dire se è una scelta per me vincente.\n  Why You Never Finish Your To-Do Lists at Work (And How to Change That) di Alex Cavoulacos\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Eat That Frog: Brian Tracy Explains the Truth About Frogs di Brian Tracy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://binick.blog/it/2022/02/18/daily-milestone/","summary":"Ho iniziato a lavorare in modalità remota a Marzo 2020, la ragione immagino la conosciamo tutti.\n Comunque se un extra terrestre dovesse leggere questo post qua potrà trovare maggiori informazioni https://wikipedia.org/wiki/COVID-19.\n L\u0026rsquo;esperienza è stata quella di molti immagino, un uso massimo ed indiscriminato di piattaforme di comunicazione ed orecchi fumanti a fine giornata.\nQuest\u0026rsquo;esperienza è andata avanti all\u0026rsquo;incirca per un anno e mezzo, 16 mesi per la precisione, fino a Luglio 2021 quando sono entrato in managed/designs.","title":"Quella volta nella quale ho assaggiato una rana"},{"content":"In un articolo precedente abbiamo visto Arricchire token JWT emessi da Azure Active Directory B2C.\nIn quell\u0026rsquo;articolo abbiamo parlato di come sia possibile aggiungere ad un JWT informazioni esterne a Microsoft Graph mediante l\u0026rsquo;uso di una Logic App ed un Blob Storage.\nIn questo invece vedremo come sia possibile creare una soluzioni che integri Azure Active Directory B2C.\nSeguendo la traccia di quanto trattato nel precedente articolo vedremo come salvare su Blob Storage dati fittizi alla registrazione di un utente.\nNote Nel resto dell\u0026rsquo;articolo ci sono riferimenti a risorse e concetti trattati nel precedente articolo al quale si rimanda. \nPanoramica della soluzione. La soluzione è cosi composta:\n Composizione della soluzione\n   read-customer-details-identity-la: rappresenta l\u0026rsquo;api il cui scopo è reperire il contenuto del blob da customersstgacc (lo storage account) customer-register-tpc: è il topic nel quale sono collezionati gli eventi di creazione di un nuovo utente customer-identity-details-filler-la: rappresenta l\u0026rsquo;api al quale spetta l\u0026rsquo;onere di generare dati fittizi che poi saranno salvati all\u0026rsquo;interno di un blob sullo customersstgacc   contoso-b2c: è il servizio di gestione degli accessi e delle identità offerto da Azure  Introduzione ad Azure Event Grid. In Azure esiste un\u0026rsquo;implementazione del pattern publish/subscribe concepita per agevolare l\u0026rsquo;integrazione e la gestione delle risorse mediante un paradigma di sviluppo ad eventi.\nMediante Event Grid sarà quindi possibile sottoscriversi a sorgenti di messaggi built-in attraverso una serie di gestori.\nQual\u0026rsquo;ora questo non fosse sufficiente è comunque possibile creare dei topic personalizzati ai quali sarà possibile sottoscriversi per riceverne gli eventi.\nCreazione di un topic personalizzato. Per la creazione di un topic è possibile fare riferimento a questa guida.\nUna scelta da fare al momento della creazione del topic riguarda lo schema del contenuto della richiesta HTTP utilizzato. Gli schemi supportati al momento sono:\n Event Grid Schema Cloud Event Schema Custom Input Schema, questo schema richiederà la creazione di un'associazione fra le proprietà dell\u0026rsquo;oggetto in ingresso e quelle richieste dallo Event Grid Schema.  Il messaggio usato in questo caso ha la seguente struttura\n1[ 2 { 3 \u0026#34;data\u0026#34;: { 4 \u0026#34;objectId\u0026#34;: \u0026#34;25100647-****-4571-****-b03e4ce72d02\u0026#34; // l\u0026#39;identificativo utile ad identificare l\u0026#39;utente 5 }, 6 \u0026#34;id\u0026#34;: \u0026#34;25100647-****-4571-****-b03e4ce72d02\u0026#34;, // l\u0026#39;identificativo univoco del messaggio, lo stesso di `data.objectId` in qesto caso 7 \u0026#34;eventType\u0026#34;: \u0026#34;Microsoft.ActiveDirectory\u0026#34;, 8 \u0026#34;subject\u0026#34;: \u0026#34;*.onmicrosoft.com\u0026#34;, 9 \u0026#34;dataVersion\u0026#34;: \u0026#34;1.0\u0026#34;, 10 \u0026#34;metadataVersion\u0026#34;: \u0026#34;1\u0026#34;, 11 \u0026#34;eventTime\u0026#34;: \u0026#34;2021-12-03T21:04:03.8504745Z\u0026#34;, 12 \u0026#34;topic\u0026#34;: \u0026#34;/subscriptions/{your-subscription-id}/resourceGroups/{your-resource-group}/providers/Microsoft.EventGrid/topics/{your-event-grid-topic}\u0026#34; 13 } 14] Emissione dell\u0026rsquo;evento di registrazione. L\u0026rsquo;invio degli eventi verso il topic avviene utilizzando un RESTful technical profile.\n1\u0026lt;TechnicalProfile Id=\u0026#34;AAD-UserEmitRegistrationEvent\u0026#34;\u0026gt; 2 \u0026lt;DisplayName\u0026gt;Emit user registration event to Event Grid.\u0026lt;/DisplayName\u0026gt; 3 \u0026lt;Protocol Name=\u0026#34;Proprietary\u0026#34; Handler=\u0026#34;Web.TPEngine.Providers.RestfulProvider, Web.TPEngine, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null\u0026#34; /\u0026gt; 4 \u0026lt;Metadata\u0026gt; 5 \u0026lt;Item Key=\u0026#34;ServiceUrl\u0026#34;\u0026gt;{Settings:CustomerRegisteredTopicUrl}\u0026lt;/Item\u0026gt; 6 \u0026lt;Item Key=\u0026#34;AuthenticationType\u0026#34;\u0026gt;ApiKeyHeader\u0026lt;/Item\u0026gt; 7 \u0026lt;Item Key=\u0026#34;SendClaimsIn\u0026#34;\u0026gt;Body\u0026lt;/Item\u0026gt; 8 \u0026lt;Item Key=\u0026#34;ClaimUsedForRequestPayload\u0026#34;\u0026gt;userRegisterEvent\u0026lt;/Item\u0026gt; 9 \u0026lt;Item Key=\u0026#34;DefaultUserMessageIfRequestFailed\u0026#34;\u0026gt;Cannot process your request right now, please try again later.\u0026lt;/Item\u0026gt; 10 \u0026lt;/Metadata\u0026gt; 11 \u0026lt;CryptographicKeys\u0026gt; 12 \u0026lt;Key Id=\u0026#34;aeg-sas-key\u0026#34; StorageReferenceId=\u0026#34;B2C_1A_CustomerRegisteredTopicSas\u0026#34; /\u0026gt; 13 \u0026lt;/CryptographicKeys\u0026gt; 14 \u0026lt;InputClaimsTransformations\u0026gt; 15 \u0026lt;InputClaimsTransformation ReferenceId=\u0026#34;GetSystemDateTime\u0026#34; /\u0026gt; 16 \u0026lt;InputClaimsTransformation ReferenceId=\u0026#34;GenerateRegistrationEventRequest\u0026#34; /\u0026gt; 17 \u0026lt;/InputClaimsTransformations\u0026gt; 18 \u0026lt;InputClaims\u0026gt; 19 \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;userRegisterEvent\u0026#34; /\u0026gt; 20 \u0026lt;/InputClaims\u0026gt; 21 \u0026lt;PersistedClaims\u0026gt; 22 \u0026lt;PersistedClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; /\u0026gt; 23 \u0026lt;/PersistedClaims\u0026gt; 24 \u0026lt;UseTechnicalProfileForSessionManagement ReferenceId=\u0026#34;SM-AAD\u0026#34; /\u0026gt; 25\u0026lt;/TechnicalProfile\u0026gt; Questo frammento di markup tradotto in comando curl, per maggiore esplicabilità, risulterebbe cosi:\n1curl -X POST -H \u0026#34;aeg-sas-key: $key\u0026#34; -d \u0026#34;$event\u0026#34; $endpoint dove i requisiti di autenticazione vengono soddisfatti dal metadato AuthenticationType al quale viene associata la chiave crittografica aeg-sas-key il cui valore viene recuperato dalla chiave B2C_1A_CustomerRegisteredTopicSas presente nella collezione delle chiavi dei criteri.\nTL;DR La scelta dello schema del topic in questo esempio è stata guidata dalle limitazioni al momento imposte dal profilo tecnico RESTful riguardo alle possibilità di costruzione della richiesta HTTP, infatti per una combinazione di criteri non risulta possibile passare informazioni nelle intestazioni e nel corpo della richiesta allo stesso tempo.\nCiò rende impossibile inviare verso un topic schemi di tipo Cloud Event in quanto il protocollo, nella versione 1.0 richiede la presenza di un'intestazione obbligatoria. \nBen più complessa è la creazione del corpo della richiesta per la quale risultano necessario:\n utilizzare le InputClaimsTransformation aggiungere due attestazioni all\u0026rsquo;interno del bagaglio userRegisterEvent e systemDateTime entrambe di tipo stringa.  Infine il profilo tecnico è stato aggiunto fra i profili tecnici di validazione di LocalAccountSignUpWithLogonEmail in modo tale che l\u0026rsquo;evento venga emesso solamente in fase di registrazione di un\u0026rsquo;utente.\nUtilizzo delle trasformazioni delle attestazioni. Durante la creazione di criteri personalizzati potremmo avere la necessità di eseguire calcoli, come ad esempio il numero di tentativi di autenticazione, che seppur molto semplici risulterebbero impossibili senza l\u0026rsquo;esecuzioni di funzioni.\nQuesto requisito trova espressività tramite le ClaimsTransformation il cui riferimento delle trasformazioni delle attestazioni contiene la lista completa delle trasformazioni utilizabili.\nNell\u0026rsquo;esempio sono stati utilizzati i metodi GetCurrentDateTime e GenerateJson\n1\u0026lt;ClaimsTransformation Id=\u0026#34;GetSystemDateTime\u0026#34; TransformationMethod=\u0026#34;GetCurrentDateTime\u0026#34;\u0026gt; 2 \u0026lt;OutputClaims\u0026gt; 3 \u0026lt;OutputClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; TransformationClaimType=\u0026#34;currentDateTime\u0026#34; /\u0026gt; 4 \u0026lt;/OutputClaims\u0026gt; 5\u0026lt;/ClaimsTransformation\u0026gt; GetSystemDateTime ha lo scopo di valorizzare l\u0026rsquo;attestazione systemDateTime\n1\u0026lt;ClaimsTransformation Id=\u0026#34;GenerateRegistrationEventRequest\u0026#34; TransformationMethod=\u0026#34;GenerateJson\u0026#34;\u0026gt; 2 \u0026lt;InputClaims\u0026gt; 3 \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;objectId\u0026#34; TransformationClaimType=\u0026#34;0.data.objectId\u0026#34; /\u0026gt; 4 \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;objectId\u0026#34; TransformationClaimType=\u0026#34;0.id\u0026#34; /\u0026gt; 5 \u0026lt;InputClaim ClaimTypeReferenceId=\u0026#34;systemDateTime\u0026#34; TransformationClaimType=\u0026#34;0.eventTime\u0026#34; /\u0026gt; 6 \u0026lt;/InputClaims\u0026gt; 7 \u0026lt;InputParameters\u0026gt; 8 \u0026lt;InputParameter Id=\u0026#34;0.dataVersion\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;1.0\u0026#34; /\u0026gt; 9 \u0026lt;InputParameter Id=\u0026#34;0.eventType\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;Microsoft.ActiveDirectory\u0026#34; /\u0026gt; 10 \u0026lt;InputParameter Id=\u0026#34;0.subject\u0026#34; DataType=\u0026#34;string\u0026#34; Value=\u0026#34;{Settings:Tenant}\u0026#34; /\u0026gt; 11 \u0026lt;/InputParameters\u0026gt; 12 \u0026lt;OutputClaims\u0026gt; 13 \u0026lt;OutputClaim ClaimTypeReferenceId=\u0026#34;userRegisterEvent\u0026#34; TransformationClaimType=\u0026#34;outputClaim\u0026#34; /\u0026gt; 14 \u0026lt;/OutputClaims\u0026gt; 15\u0026lt;/ClaimsTransformation\u0026gt; GenerateRegistrationEventRequest ha invece l\u0026rsquo;onere di costruire il JSON e valorizzare l\u0026rsquo;attestazione userRegisterEvent.\nConclusioni. In questo articolo abbiamo visto come mediante Identity Experience Framework sia possibile integrare un tenant B2C con la nostra infrastruttura ed aprire eventuali scenari di sviluppo interessanti.\nPer farlo abbiamo toccato Azure Event Grid e come creare un Event Grid Topic.\nInfine come sia possibile manipolare delle attestazioni ed utilizzarle all\u0026rsquo;interno dei profili tecnici.\nSe foste interessati all’esempio completo lo potrete trovare al seguente indirizzo https://github.com/binick/samples/tree/master/src/enrich-a-jwt-token-with-ief.\n","permalink":"https://binick.blog/it/2022/01/08/aadb2c-subscribe-to-user-registration-event/","summary":"In un articolo precedente abbiamo visto Arricchire token JWT emessi da Azure Active Directory B2C.\nIn quell\u0026rsquo;articolo abbiamo parlato di come sia possibile aggiungere ad un JWT informazioni esterne a Microsoft Graph mediante l\u0026rsquo;uso di una Logic App ed un Blob Storage.\nIn questo invece vedremo come sia possibile creare una soluzioni che integri Azure Active Directory B2C.\nSeguendo la traccia di quanto trattato nel precedente articolo vedremo come salvare su Blob Storage dati fittizi alla registrazione di un utente.","title":"Sviluppare soluzioni integrate con Active Directory B2C ed Azure Event Grid."},{"content":"","permalink":"https://binick.blog/it/2021/12/27/enrich-a-jwt-token-with-ief/","summary":"Personalizzare un JSON Web Token emesso da Azure Active Directory B2C con informazioni presenti su un sistema esterno è possibile: è sufficiente, infatti, sfruttare le possibilità di personalizzazione offerte dai criteri personalizzati.","title":"Arricchire token JWT emessi da Azure Active Directory B2C"},{"content":"","permalink":"https://binick.blog/it/about-me/","summary":"Chi sono","title":"Chi sono"}]